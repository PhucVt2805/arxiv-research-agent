import os
from typing import Any
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.agents import create_agent

from src.model import ArxivPaper
from src.utils.log_config import get_logger
from src.agent.tools import web_search, read_full_paper

logger = get_logger("AgentGraph")

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite", 
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.5,
    streaming=True
)

tools = [web_search, read_full_paper]

SYSTEM_PROMPT = """Báº¡n lÃ  má»™t Trá»£ lÃ½ NghiÃªn cá»©u AI (AI Research Assistant) cao cáº¥p.
Báº¡n Ä‘ang há»— trá»£ ngÆ°á»i dÃ¹ng tÃ¬m hiá»ƒu vá» má»™t bÃ i bÃ¡o khoa há»c cá»¥ thá»ƒ.

QUY TRÃŒNH SUY LUáº¬N:
1. Äá»c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
2. Kiá»ƒm tra xem thÃ´ng tin cÃ³ trong pháº§n "TÃ“M Táº®T BÃ€I BÃO" (Abstract) Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p sáºµn hay khÃ´ng.
3. Náº¿u cÃ¢u há»i vá» kiáº¿n thá»©c chung (vÃ­ dá»¥: "Transformer lÃ  gÃ¬?", "YOLO ra Ä‘á»i nÄƒm nÃ o?"), hÃ£y dÃ¹ng cÃ´ng cá»¥ `web_search`.
4. Náº¿u cÃ¢u há»i yÃªu cáº§u chi tiáº¿t SÃ‚U trong bÃ i bÃ¡o (vÃ­ dá»¥: "CÃ´ng thá»©c loss function lÃ  gÃ¬?", "Káº¿t quáº£ báº£ng 3 tháº¿ nÃ o?"), hÃ£y dÃ¹ng cÃ´ng cá»¥ `read_full_paper` vá»›i ID bÃ i bÃ¡o.
5. Sau khi cÃ³ thÃ´ng tin tá»« tool, hÃ£y tá»•ng há»£p vÃ  tráº£ lá»i báº±ng Tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p.

LÆ°u Ã½:
- KHÃ”NG gá»i tool `read_full_paper` náº¿u chá»‰ há»i tÃ³m táº¯t hoáº·c thÃ´ng tin cÆ¡ báº£n.
- Khi gá»i `read_full_paper`, hÃ£y kiÃªn nháº«n Ä‘á»c ná»™i dung tráº£ vá».
"""

agent_executor = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)

async def chat_with_paper(paper_id: str, user_query: str, history: list) -> Any:
    """
    HÃ m entrypoint Ä‘á»ƒ gá»i Agent.
    """
    paper = await ArxivPaper.get(paper_id)
    if not paper:
        yield "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin bÃ i bÃ¡o nÃ y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."
        return

    context_msg = f"""
    --- CONTEXT BÃ€I BÃO ÄANG THáº¢O LUáº¬N ---
    ID: {paper.id}
    Title: {paper.title}
    Abstract: {paper.summary}
    ---------------------------------------
    """

    langchain_history = [SystemMessage(content=context_msg)]
    for msg in history:
        if msg['role'] == 'user':
            langchain_history.append(HumanMessage(content=msg['content']))
        elif msg['role'] == 'assistant':
            langchain_history.append(AIMessage(content=msg['content']))
    
    langchain_history.append(HumanMessage(content=user_query))

    try:
        async for event in agent_executor.astream_events(
            {"messages": langchain_history},
            version="v1"
        ):
            kind = event["event"]
            if kind == "on_tool_start":
                tool_name = event['name']
                if tool_name == "web_search":
                    yield f"\n\n*ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin trÃªn web...*\n\n"
                elif tool_name == "read_full_paper":
                    yield f"\n\n*ğŸ“¥ Äang táº£i vÃ  Ä‘á»c toÃ n vÄƒn bÃ i bÃ¡o (Full PDF)...*\n\n"

            elif kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    yield content

    except Exception as e:
        logger.error(f"Lá»—i Agent: {e}", exc_info=True)
        yield f"\n\n[Lá»—i há»‡ thá»‘ng: {str(e)}]"